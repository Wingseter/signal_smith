"""
GPT í€€íŠ¸ ë¶„ì„ê°€

ê¸°ìˆ ì  ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” GPT ê¸°ë°˜ ë¶„ì„ê°€
- RSI, MACD, ë³¼ë¦°ì €ë°´ë“œ ë“± ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„
- ê±°ë˜ëŸ‰ ë¶„ì„
- ì°¨íŠ¸ íŒ¨í„´ ë¶„ì„
- ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê´€ì ì˜ íˆ¬ì ë¹„ìœ¨ ì œì•ˆ
"""

import logging
from typing import Optional
import json

from openai import AsyncOpenAI

from app.config import settings
from .models import CouncilMessage, AnalystRole

logger = logging.getLogger(__name__)


class QuantAnalyst:
    """GPT ê¸°ë°˜ í€€íŠ¸ ë¶„ì„ê°€"""

    SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì „ë¬¸ í€€íŠ¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ê¸°ìˆ ì  ë¶„ì„ê³¼ ìˆ˜ì¹˜ ê¸°ë°˜ íˆ¬ì íŒë‹¨ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

ë¶„ì„ ì˜ì—­:
1. ê¸°ìˆ ì  ì§€í‘œ: RSI, MACD, ë³¼ë¦°ì €ë°´ë“œ, ì´ë™í‰ê· ì„ 
2. ê±°ë˜ëŸ‰ ë¶„ì„: ê±°ë˜ëŸ‰ ì¶”ì´, ê±°ë˜ëŒ€ê¸ˆ
3. ì°¨íŠ¸ íŒ¨í„´: ì§€ì§€/ì €í•­ì„ , ì¶”ì„¸ì„ , íŒ¨í„´
4. ë¦¬ìŠ¤í¬ ê´€ë¦¬: ë³€ë™ì„±, ì†ì ˆê°€, í¬ì§€ì…˜ ì‚¬ì´ì§•

ì‘ë‹µ í˜•ì‹:
- ë¶„ì„ ê²°ê³¼ëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì œì‹œ
- íˆ¬ì ë¹„ìœ¨ì€ ì´ ìê¸ˆ ëŒ€ë¹„ %ë¡œ ì œì•ˆ
- í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€"""

    ANALYSIS_PROMPT = """ë‹¤ìŒ ì¢…ëª©ì— ëŒ€í•œ í€€íŠ¸/ê¸°ìˆ ì  ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

[ì¢…ëª© ì •ë³´]
ì¢…ëª©ì½”ë“œ: {symbol}
ì¢…ëª©ëª…: {company_name}
ë‰´ìŠ¤: {news_title}

[ì´ì „ ëŒ€í™”]
{conversation}

[ìš”ì²­]
{request}

[ì‘ë‹µ í˜•ì‹]
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "analysis": "ê¸°ìˆ ì  ë¶„ì„ ë‚´ìš© (2-3ë¬¸ì¥)",
    "score": 1-10 ì‚¬ì´ ì ìˆ˜,
    "suggested_percent": ì œì•ˆ íˆ¬ì ë¹„ìœ¨ (0-100),
    "reasoning": "íˆ¬ì ë¹„ìœ¨ ì‚°ì • ê·¼ê±°",
    "risk_factors": ["ë¦¬ìŠ¤í¬ ìš”ì†Œ 1", "ë¦¬ìŠ¤í¬ ìš”ì†Œ 2"],
    "reply_to_other": "ë‹¤ë¥¸ ë¶„ì„ê°€ì—ê²Œ í•˜ê³  ì‹¶ì€ ë§ (ì„ íƒ)"
}}"""

    def __init__(self):
        self._client: Optional[AsyncOpenAI] = None
        self._initialized = False

    def _initialize(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if self._initialized:
            return

        if not settings.openai_api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self._client = AsyncOpenAI(api_key=settings.openai_api_key)
        self._initialized = True
        logger.info(f"GPT í€€íŠ¸ ë¶„ì„ê°€ ì´ˆê¸°í™” (ëª¨ë¸: {settings.openai_model})")

    def _build_conversation(self, messages: list[CouncilMessage]) -> str:
        """ì´ì „ ëŒ€í™” ë‚´ìš© êµ¬ì„±"""
        if not messages:
            return "(ì²« ë²ˆì§¸ ë°œì–¸ì…ë‹ˆë‹¤)"

        lines = []
        for msg in messages[-6:]:  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ
            speaker = msg.speaker
            content = msg.content[:200]  # ê¸¸ì´ ì œí•œ
            lines.append(f"[{speaker}]: {content}")

        return "\n".join(lines)

    async def analyze(
        self,
        symbol: str,
        company_name: str,
        news_title: str,
        previous_messages: list[CouncilMessage],
        request: str = "ê¸°ìˆ ì  ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  íˆ¬ì ë¹„ìœ¨ì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
    ) -> CouncilMessage:
        """í€€íŠ¸ ë¶„ì„ ìˆ˜í–‰"""
        self._initialize()

        conversation = self._build_conversation(previous_messages)

        prompt = self.ANALYSIS_PROMPT.format(
            symbol=symbol,
            company_name=company_name,
            news_title=news_title,
            conversation=conversation,
            request=request,
        )

        try:
            response = await self._client.chat.completions.create(
                model=settings.openai_model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.7,
                max_tokens=500,
            )

            response_text = response.choices[0].message.content

            # JSON íŒŒì‹± ì‹œë„
            try:
                # JSON ë¸”ë¡ ì¶”ì¶œ
                if "```json" in response_text:
                    json_str = response_text.split("```json")[1].split("```")[0]
                elif "```" in response_text:
                    json_str = response_text.split("```")[1].split("```")[0]
                else:
                    json_str = response_text

                data = json.loads(json_str.strip())

                content = f"""ğŸ“Š **í€€íŠ¸ ë¶„ì„ ê²°ê³¼**

{data.get('analysis', '')}

â€¢ ê¸°ìˆ ì  ì ìˆ˜: {data.get('score', 5)}/10
â€¢ ì œì•ˆ íˆ¬ì ë¹„ìœ¨: {data.get('suggested_percent', 0)}%
â€¢ ê·¼ê±°: {data.get('reasoning', '')}

âš ï¸ ë¦¬ìŠ¤í¬ ìš”ì†Œ:
{chr(10).join(f"- {r}" for r in data.get('risk_factors', []))}"""

                if data.get('reply_to_other'):
                    content += f"\n\nğŸ’¬ {data.get('reply_to_other')}"

            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
                content = f"ğŸ“Š **í€€íŠ¸ ë¶„ì„**\n\n{response_text}"
                data = {"score": 5, "suggested_percent": 0}

            return CouncilMessage(
                role=AnalystRole.GPT_QUANT,
                speaker="GPT í€€íŠ¸ ë¶„ì„ê°€",
                content=content,
                data=data,
            )

        except Exception as e:
            logger.error(f"GPT í€€íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return CouncilMessage(
                role=AnalystRole.GPT_QUANT,
                speaker="GPT í€€íŠ¸ ë¶„ì„ê°€",
                content=f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                data={"error": str(e)},
            )

    async def respond_to(
        self,
        symbol: str,
        company_name: str,
        news_title: str,
        previous_messages: list[CouncilMessage],
        other_analysis: str,
    ) -> CouncilMessage:
        """ë‹¤ë¥¸ ë¶„ì„ê°€ì˜ ì˜ê²¬ì— ì‘ë‹µ"""
        request = f"""í€ë”ë©˜í„¸ ë¶„ì„ê°€ì˜ ì˜ê²¬ì„ ê²€í† í•˜ê³  ì‘ë‹µí•´ì£¼ì„¸ìš”:

{other_analysis}

ë™ì˜í•˜ê±°ë‚˜ ë°˜ëŒ€ ì˜ê²¬ì´ ìˆë‹¤ë©´ ê·¼ê±°ì™€ í•¨ê»˜ ì œì‹œí•˜ê³ ,
ìµœì¢… íˆ¬ì ë¹„ìœ¨ì— ëŒ€í•œ ì¡°ì • ì˜ê²¬ì„ ì œì•ˆí•´ì£¼ì„¸ìš”."""

        return await self.analyze(
            symbol=symbol,
            company_name=company_name,
            news_title=news_title,
            previous_messages=previous_messages,
            request=request,
        )


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
quant_analyst = QuantAnalyst()
